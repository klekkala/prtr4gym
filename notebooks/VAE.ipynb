{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as Datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from RES_VAE import VAE as VAE\n",
    "from vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 64\n",
    "lr = 1e-4\n",
    "nepoch = 100\n",
    "start_epoch = 0\n",
    "dataset_root = \"../Documents/\"\n",
    "save_dir = os.getcwd()\n",
    "model_name = \"STL10_8\"\n",
    "load_checkpoint  = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "GPU_indx  = 0\n",
    "device = torch.device(GPU_indx if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_STL10(transform, batch_size, download = True, root = \"/data\"):\n",
    "    print(\"Loading trainset...\")\n",
    "    trainset = Datasets.STL10(root=root, split='unlabeled', transform=transform, download=download)\n",
    "    \n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    print(\"Loading testset...\")\n",
    "    testset = Datasets.STL10(root=root, split='test', download=download, transform=transform)\n",
    "\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD way of getting features and calculating loss - Not used\n",
    "\n",
    "#create an empty layer that will simply record the feature map passed to it.\n",
    "class GetFeatures(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GetFeatures, self).__init__()\n",
    "        self.features = None\n",
    "    def forward(self, x):\n",
    "        self.features = x\n",
    "        return x\n",
    "\n",
    "#download the pre-trained weights of the VGG-19 and append them to an array of layers .\n",
    "#we insert a GetFeatures layer after a relu layer.\n",
    "#layers_deep controls how deep we go into the network\n",
    "def get_feature_extractor(layers_deep = 7):\n",
    "    C_net = models.vgg19(pretrained=True).to(device)\n",
    "    C_net = C_net.eval()\n",
    "    \n",
    "    layers = []\n",
    "    for i in range(layers_deep):\n",
    "        layers.append(C_net.features[i])\n",
    "        if isinstance(C_net.features[i], nn.ReLU):\n",
    "            layers.append(GetFeatures())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "#this function calculates the L2 loss (MSE) on the feature maps copied by the layers_deep\n",
    "#between the reconstructed image and the origional\n",
    "def feature_loss(img, recon_data, feature_extractor):\n",
    "    img_cat = torch.cat((img, torch.sigmoid(recon_data)), 0)\n",
    "    out = feature_extractor(img_cat)\n",
    "    loss = 0\n",
    "    for i in range(len(feature_extractor)):\n",
    "        if isinstance(feature_extractor[i], GetFeatures):\n",
    "            loss += (feature_extractor[i].features[:(img.shape[0])] - feature_extractor[i].features[(img.shape[0]):]).pow(2).mean()\n",
    "    return loss/(i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear scaling the learning rate down\n",
    "def lr_Linear(epoch_max, epoch, lr):\n",
    "    lr_adj = ((epoch_max-epoch)/epoch_max)*lr\n",
    "    set_lr(lr = lr_adj)\n",
    "\n",
    "def set_lr(lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "def vae_loss(recon, x, mu, logvar):\n",
    "    recon_loss = F.binary_cross_entropy_with_logits(recon, x)\n",
    "    KL_loss = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp()).mean()\n",
    "    loss = recon_loss + 0.01 * KL_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Resize(image_size), T.ToTensor()])\n",
    "\n",
    "trainloader, testloader = get_data_STL10(transform, batch_size, download=False, root=dataset_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a test image batch from the testloader to visualise the reconstruction quality\n",
    "dataiter = iter(testloader)\n",
    "test_images, _ = dataiter.next()\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "out = vutils.make_grid(test_images[0:8])\n",
    "plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the feature loss module\n",
    "\n",
    "# load the state dict for vgg19\n",
    "state_dict = torch.hub.load_state_dict_from_url('https://download.pytorch.org/models/vgg19-dcbb9e9d.pth')\n",
    "# manually create the feature extractor from vgg19\n",
    "feature_extractor = VGG19(channel_in=3)\n",
    "\n",
    "# loop through the loaded state dict and our vgg19 features net,\n",
    "# loop will stop when net.parameters() runs out - so we never get to the \"classifier\" part of vgg\n",
    "for ((name, source_param), target_param) in zip(state_dict.items(), feature_extractor.parameters()):\n",
    "    target_param.data = source_param.data\n",
    "    target_param.requires_grad = False\n",
    "    \n",
    "feature_extractor = feature_extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create VAE network\n",
    "vae_net = VAE(channel_in=3, ch=64).to(device)\n",
    "# setup optimizer\n",
    "optimizer = optim.Adam(vae_net.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "#Loss function\n",
    "BCE_Loss = nn.BCEWithLogitsLoss()\n",
    "loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the save directory if it does note exist\n",
    "if not os.path.isdir(save_dir + \"/Models\"):\n",
    "    os.makedirs(save_dir + \"/Models\")\n",
    "if not os.path.isdir(save_dir + \"/Results\"):\n",
    "    os.makedirs(save_dir + \"/Results\")\n",
    "\n",
    "if load_checkpoint:\n",
    "    checkpoint = torch.load(save_dir + \"/Models/\" + model_name + \"_\" + str(image_size) + \".pt\", map_location = \"cpu\")\n",
    "    print(\"Checkpoint loaded\")\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    vae_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "    loss_log = checkpoint[\"loss_log\"]\n",
    "else:\n",
    "    #If checkpoint does exist raise an error to prevent accidental overwriting\n",
    "    if os.path.isfile(save_dir + \"/Models/\" + model_name + \"_\" + str(image_size) + \".pt\"):\n",
    "        raise ValueError(\"Warning Checkpoint exists\")\n",
    "    else:\n",
    "        print(\"Starting from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(start_epoch, nepoch, leave=False):\n",
    "    lr_Linear(nepoch, epoch, lr)\n",
    "    vae_net.train()\n",
    "    for i, (images, _) in enumerate(tqdm(trainloader, leave=False)):\n",
    "\n",
    "        recon_data, mu, logvar = vae_net(images.to(device))\n",
    "        #VAE loss\n",
    "        loss = vae_loss(recon_data, images.to(device), mu, logvar)        \n",
    "        \n",
    "        #Perception loss\n",
    "        loss += feature_extractor(torch.cat((torch.sigmoid(recon_data), images.to(device)), 0))\n",
    "    \n",
    "        loss_log.append(loss.item())\n",
    "        vae_net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #In eval mode the model will use mu as the encoding instead of sampling from the distribution\n",
    "    vae_net.eval()\n",
    "    with torch.no_grad():\n",
    "        recon_data, _, _ = vae_net(test_images.to(device))\n",
    "        vutils.save_image(torch.cat((torch.sigmoid(recon_data.cpu()), test_images),2),\"%s/%s/%s_%d.png\" % (save_dir, \"Results\" , model_name, image_size))\n",
    "\n",
    "        #Save a checkpoint\n",
    "        torch.save({\n",
    "                    'epoch'                         : epoch,\n",
    "                    'loss_log'                      : loss_log,\n",
    "                    'model_state_dict'              : vae_net.state_dict(),\n",
    "                    'optimizer_state_dict'          : optimizer.state_dict()\n",
    "\n",
    "                     }, save_dir + \"/Models/\" + model_name + \"_\" + str(image_size) + \".pt\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
