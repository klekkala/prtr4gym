# On a single GPU, this achieves maximum reward in ~15-20 minutes.
#
# $ python train.py -f tuned_configs/pong-ppo.yaml
#
spaceinvaders-ppo:
    env: BeamRiderNoFrameskip-v4
    run: PPO
    config:
        # Works for both torch and tf.
        framework: torch
        lambda: 0.95
        kl_coeff: 0.5
        clip_rewards: True
        clip_param: 0.1
        vf_clip_param: 10.0
        entropy_coeff: 0.01
        train_batch_size: 5000
        rollout_fragment_length: 100
        sgd_minibatch_size: 500
        num_sgd_iter: 10
        num_workers: 10
        num_gpus: 1
        num_envs_per_worker: 5
        batch_mode: truncate_episodes
        observation_filter: NoFilter
        lr: 0.0001
        model:
            use_lstm: true
            conv_activation: elu
            dim: 42
            grayscale: true
            zero_mean: false
            # Reduced channel depth and kernel size from default
            conv_filters: [
                [32, [3, 3], 2],
                [32, [3, 3], 2],
                [32, [3, 3], 2],
                [32, [3, 3], 2],
            ]